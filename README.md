# Word2Vec
Word2Vec is a technique for computing vector representations of words, capturing semantic relationships based on the context in which words appear. The model learns word embeddings by either predicting the context of a word (Continuous Bag of Words, CBOW) or predicting the word given a context (Skip-gram).

*Application:*
- *Semantic Similarity:* Helps in understanding semantic relationships between words in customer reviews.
- *Enhanced Recommendations:* Provides contextually relevant product suggestions based on reviews.
